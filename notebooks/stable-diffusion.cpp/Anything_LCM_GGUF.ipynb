{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzwing/AI-related/blob/master/notebooks/stable-diffusion.cpp/Anything_LCM_GGUF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --force-reinstall huggingface_hub[hf_transfer]"
      ],
      "metadata": {
        "id": "h4Xe5Suq4koh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBxcmSgq7Bed"
      },
      "outputs": [],
      "source": [
        "# prepare\n",
        "!rm -rf sample_data\n",
        "!mkdir -p Anything-LCM-GGUF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "p-FGWJXl4n4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2RBV70CuKN4"
      },
      "outputs": [],
      "source": [
        "# get original model\n",
        "!sudo apt-get install aria2 -y\n",
        "!mkdir -p Anything-LCM\n",
        "!echo -e \"https://huggingface.co/mzwing/Anything-LCM-GGUF/resolve/main/anything_v30-LCM.safetensors?download=true\\n out=anything_v30-LCM.safetensors\" > download.txt\n",
        "!aria2c -c -x16 -d Anything-LCM --input-file=download.txt\n",
        "!rm -rf download.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install aria2 -y\n",
        "!aria2c -c -x16 -d Anything-LCM-GGUF https://huggingface.co/mzwing/Anything-LCM-GGUF/resolve/main/anything_v30-LCM.q8_0.gguf?download=true -o anything_v30-LCM.q8_0.gguf"
      ],
      "metadata": {
        "id": "V4imzx9ljH8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2bDPao1jam1"
      },
      "outputs": [],
      "source": [
        "# get compile result (CPU)\n",
        "!aria2c -c -x16 https://github.com/MZWNET/actions/releases/download/sd-master-48bcce4/sd-master-48bcce4-bin-linux-avx2-openblas-x64.zip\n",
        "!unzip sd-master-48bcce4-bin-linux-avx2-cublas-cu121-x64.zip -d .\n",
        "!rm -rf sd-master-48bcce4-bin-linux-avx2-cublas-cu121-x64.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QLXZbjO6Hde"
      },
      "outputs": [],
      "source": [
        "# prepare for GPU\n",
        "!sudo apt-get install nvidia-cuda-toolkit -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVboRtai6Kgx"
      },
      "outputs": [],
      "source": [
        "# get compile result (GPU)\n",
        "!aria2c -c -x16 https://github.com/MZWNET/actions/releases/download/sd-master-48bcce4/sd-master-48bcce4-bin-linux-avx2-cublas-cu121-x64.zip\n",
        "!unzip sd-master-48bcce4-bin-linux-avx2-cublas-cu121-x64.zip -d .\n",
        "!rm -rf sd-master-48bcce4-bin-linux-avx2-cublas-cu121-x64.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AdSBJlEPNyo"
      },
      "outputs": [],
      "source": [
        "# quantize\n",
        "import concurrent.futures\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "parameters = [ \"f16\", \"q8_0\", \"q5_1\", \"q5_0\", \"q4_1\", \"q4_0\" ]\n",
        "models = [ \"anything_v30-LCM.safetensors\" ]\n",
        "\n",
        "tasks = [(model, param) for model in models for param in parameters]\n",
        "\n",
        "def run_command(task):\n",
        "    model, param = task\n",
        "    model_name = model.split('.')[0]\n",
        "    os.system(f\"./sd -M convert -m Anything-LCM/{model} -o Anything-LCM-GGUF/{model_name}.{param}.gguf --type {param}\")\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    list(tqdm(executor.map(run_command, tasks), total=len(tasks)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "!./sd -m Anything-LCM/anything_v30-LCM.safetensors -p \"1girl, beautiful, school-uniform, nsfw\" --cfg-scale 1 --steps 4 -s -1 -v -o test.png"
      ],
      "metadata": {
        "id": "NCvCV75iGd9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMbY6etBWH0c"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "!./sd -m Anything-LCM-GGUF/anything_v30-LCM.q8_0.gguf -p \"1girl, beautiful, school-uniform, nsfw\" --cfg-scale 1 --steps 4 -s -1 -v -o test.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyxqF66WEUqx"
      },
      "outputs": [],
      "source": [
        "!HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli upload --repo-type model --commit-message \"GGUF model commit (made with stable-diffusion.cpp commit 583cc5b)\" Anything-LCM-GGUF ./Anything-LCM-GGUF"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}